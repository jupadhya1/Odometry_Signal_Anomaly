{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"logs\"):\n",
    "    os.makedirs(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from importlib import reload\n",
    "import logging\n",
    "reload(logging)\n",
    "\n",
    "import time\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', \n",
    "                    filename=f'logs/{int(time.time())}.log',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import zipfile\n",
    "import json\n",
    "\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "from minio import Minio\n",
    "from minio.error import ResponseError\n",
    "\n",
    "import boto3\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "minioClient = Minio(config[\"minio_config\"][\"endpoint_url\"].replace(\"http://\",\"\").rstrip(\"/\"),\n",
    "                    access_key=config[\"minio_config\"][\"aws_access_key_id\"],\n",
    "                    secret_key=config[\"minio_config\"][\"aws_secret_access_key\"],\n",
    "                    secure=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INPUT_RAW_FILES = \"raw/4018_nominal/*zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Unnamed: 0\", \"Unnamed: 1\", \"speedLimit\", \n",
    "\"trainSpeed\", \n",
    "\"targetSpeed\", \n",
    "\"TransponderOK\", \n",
    "\"MSTEP_A_axle1RawSpeed\", \n",
    "\"MSTEP_A_axle2RawSpeed\", \n",
    "\"warningSpeed\", \n",
    "\"line\",\n",
    "\"VehicleID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NROWS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_element(l, old, new):\n",
    "    return [new if x==old else x for x in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagnostics_df_from_bytes(bytes_data, cols=None, nrows=None):\n",
    "    \"\"\"Returns dataframe object from a bytes object\n",
    "    representing a csv file extracted from a zip file.\"\"\"\n",
    "    \n",
    "    # string representation of the data\n",
    "    s=str(bytes_data,'utf-8')\n",
    "    \n",
    "    # reading the file content to get the header as a string,\n",
    "    # to check if fields defined in features_dtypes_dict exists in header\n",
    "    header_proxy = s[:10000].split(\",\")\n",
    "    \n",
    "    cols_corrected = cols.copy()\n",
    "    # rename axle variables if needed\n",
    "    if \"MSTEP_A_axle1RawSpeed\" not in header_proxy:\n",
    "        cols_corrected = replace_element(cols_corrected, \"MSTEP_A_axle1RawSpeed\", \"axle1RawSpeed\")\n",
    "    if \"MSTEP_A_axle2RawSpeed\" not in header_proxy:\n",
    "        cols_corrected = replace_element(cols_corrected, \"MSTEP_A_axle2RawSpeed\", \"axle2RawSpeed\")\n",
    "\n",
    "    data = StringIO(s)\n",
    "    df = pd.read_csv(data, \n",
    "                     nrows=nrows, \n",
    "                     usecols=cols_corrected)\n",
    "    \n",
    "    # rename unnamed variables\n",
    "    df = df.rename({\"Unnamed: 0\":\"TimeStamp\", \n",
    "                    \"Unnamed: 1\":\"Record Number\"}, \n",
    "                   axis=1)\n",
    "\n",
    "    # rename axle variables if needed\n",
    "    if \"MSTEP_A_axle1RawSpeed\" in df.columns:\n",
    "        df = df.rename({\"MSTEP_A_axle1RawSpeed\":\"axle1RawSpeed\"}, axis=1)\n",
    "    if \"MSTEP_A_axle2RawSpeed\" in df.columns:\n",
    "        df = df.rename({\"MSTEP_A_axle2RawSpeed\":\"axle2RawSpeed\"}, axis=1)\n",
    "    \n",
    "    # Replacing * by previous numerical value, since it means \"no change in value\"\n",
    "    df.replace(\"*\", np.nan, inplace=True)\n",
    "    df.fillna(method=\"ffill\", inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df_to_disk(df, outname):\n",
    "    logging.info(f\"writing dataframe to {outname} on disk\")\n",
    "    if os.path.dirname(outname) != \"\":\n",
    "        os.makedirs(os.path.dirname(outname), exist_ok=True)\n",
    "    df.to_csv(outname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df_to_minio(df, outname, bucket_name, minioclient):\n",
    "    logging.info(f\"writing dataframe to {outname} in minio bucket {bucket_name}\")\n",
    "    csv_bytes = df.to_csv().encode('utf-8')\n",
    "    csv_buffer = BytesIO(csv_bytes)\n",
    "\n",
    "    if not minioclient.bucket_exists(bucket_name):\n",
    "        minioclient.make_bucket(bucket_name)\n",
    "    minioclient.put_object(bucket_name, \n",
    "                           outname,  \n",
    "                           data=csv_buffer,           \n",
    "                           length=len(csv_bytes), \n",
    "                           content_type='application/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_processed_files(text, logfile=\"processedfiles.csv\"):\n",
    "    if os.path.exists(logfile):\n",
    "        is_processed = False\n",
    "        with open(logfile, \"r\") as file:\n",
    "            for line in file:\n",
    "                if text in line:\n",
    "                    is_processed = True\n",
    "                    break\n",
    "                    \n",
    "        if not is_processed: # adding file if it is not processed\n",
    "            with open(logfile, \"a\") as file:\n",
    "                file.write(f\"{text}\\n\") # append missing data\n",
    "    \n",
    "    else: # creating file if it doesn't exist\n",
    "        with open(logfile, \"w\") as file:\n",
    "            file.write(f\"{text}\\n\") # append missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_is_processed(text, logfile=\"processedfiles.csv\"):\n",
    "    if not os.path.exists(logfile):\n",
    "        return False\n",
    "\n",
    "    filelist = pd.read_csv(logfile, header=None).values.flatten()\n",
    "    if text in filelist:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_BUCKET_NAME = \"guillaume\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client(\"s3\", \n",
    "                      endpoint_url=config[\"minio_config\"][\"endpoint_url\"],\n",
    "                      aws_access_key_id=config[\"minio_config\"][\"aws_access_key_id\"],\n",
    "                      aws_secret_access_key=config[\"minio_config\"][\"aws_secret_access_key\"],\n",
    "                      region_name=config[\"minio_config\"][\"region_name\"])\n",
    "\n",
    "paginator = client.get_paginator(\"list_objects_v2\")\n",
    "\n",
    "files = list()\n",
    "for page in paginator.paginate(Bucket=INPUT_BUCKET_NAME):\n",
    "    if \"Contents\" in page.keys():\n",
    "        for obj in page[\"Contents\"]:\n",
    "            if \"/Output Zip Files/\" in obj[\"Key\"] and obj[\"Key\"].endswith(\".zip\"):\n",
    "                files.append(obj[\"Key\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(f):\n",
    "        \n",
    "#     time.sleep(np.random.randint(20,50)/1000)\n",
    "#     pass\n",
    "    if file_is_processed(f):\n",
    "        logging.info(f\"{f} is already processed.\")\n",
    "        return \"processed\"\n",
    "\n",
    "#     minioClient = Minio(config[\"minio_config\"][\"endpoint_url\"].replace(\"http://\",\"\").rstrip(\"/\"),\n",
    "#                     access_key=config[\"minio_config\"][\"aws_access_key_id\"],\n",
    "#                     secret_key=config[\"minio_config\"][\"aws_secret_access_key\"],\n",
    "#                     secure=False)\n",
    "    \n",
    "    data = minioClient.get_object(INPUT_BUCKET_NAME, f)\n",
    "    \n",
    "    try:\n",
    "        zf = zipfile.ZipFile(BytesIO(data.read()))\n",
    "    except zipfile.BadZipFile as bzf:\n",
    "        logging.info(f\"{f} is a bad zip file.\")\n",
    "        log_processed_files(f)\n",
    "        return \"bad zip file\"\n",
    "\n",
    "    archived_files = zf.namelist()\n",
    "    diagnostic_files = [n for n in archived_files if \"Diagno\" in n and n.endswith(\"csv\")]\n",
    "        \n",
    "    dfs = []\n",
    "    for filename in diagnostic_files:\n",
    "        try:\n",
    "            data = zf.read(filename)\n",
    "        except KeyError:\n",
    "            logging.info(f\"Did not find {filename} in zip file {f}.\")\n",
    "        else:\n",
    "            df = get_diagnostics_df_from_bytes(bytes_data=data, \n",
    "                                               cols=cols,\n",
    "                                               nrows=NROWS)\n",
    "            if df is None:\n",
    "                logging.info(f\"{f} is skipped.\")\n",
    "                return \"problem in diagnostic file\"\n",
    "            else:\n",
    "                dfs.append(df)\n",
    "\n",
    "    \n",
    "    df_filt = pd.concat(dfs)\n",
    "    file_info = df_filt.set_index(pd.to_datetime(df_filt[\"TimeStamp\"])).sort_index().iloc[0]\n",
    "    vid = file_info[\"VehicleID\"]\n",
    "    ymd = file_info.name.strftime(\"%Y-%m-%d\")\n",
    "    output_csv_name = f\"filtered/{vid}_{ymd}.csv\"\n",
    "#     write_df_to_disk(df_filt, output_csv_name)\n",
    "    write_df_to_minio(df_filt, output_csv_name, \"odometryclassification\", minioClient)\n",
    "    log_processed_files(f)\n",
    "    return \"success\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_proc = 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with ProcessPoolExecutor(max_workers=n_proc) as pool:\n",
    "    with tqdm(total=len(files)) as progress:\n",
    "        futures = []\n",
    "\n",
    "        for file in files:\n",
    "            future = pool.submit(process_file, file)\n",
    "            future.add_done_callback(lambda p: progress.update())\n",
    "#             futures.append(future)\n",
    "\n",
    "#         results = []\n",
    "#         for future in futures:\n",
    "#             result = future.result()\n",
    "#             results.append(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653d72c5898e4c1c9e436ee487b4b928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=834), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ac0a3c733c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprocess_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-2945ab1f7147>\u001b[0m in \u001b[0;36mprocess_file\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mzf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBadZipFile\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbzf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{f} is a bad zip file.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;31m# cStringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m                 \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for f in tqdm(files, total=len(files)):\n",
    "    process_file(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
